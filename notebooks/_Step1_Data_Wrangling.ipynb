{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling of Existing US Accident and Weather Dataset\n",
    "In this initial step I'll fill or remove null values, add useful columns, extract outliers and make corrections.\n",
    "\n",
    "This dataset was found at https://osu.app.box.com/v/us-accidents-dec19 and unzipped with 7-Zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/data/US_Accidents_Dec19.csv', parse_dates = ['Start_Time', 'End_Time'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2974335 entries, 0 to 2974334\n",
      "Data columns (total 49 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   ID                     object        \n",
      " 1   Source                 object        \n",
      " 2   TMC                    float64       \n",
      " 3   Severity               int64         \n",
      " 4   Start_Time             datetime64[ns]\n",
      " 5   End_Time               datetime64[ns]\n",
      " 6   Start_Lat              float64       \n",
      " 7   Start_Lng              float64       \n",
      " 8   End_Lat                float64       \n",
      " 9   End_Lng                float64       \n",
      " 10  Distance(mi)           float64       \n",
      " 11  Description            object        \n",
      " 12  Number                 float64       \n",
      " 13  Street                 object        \n",
      " 14  Side                   object        \n",
      " 15  City                   object        \n",
      " 16  County                 object        \n",
      " 17  State                  object        \n",
      " 18  Zipcode                object        \n",
      " 19  Country                object        \n",
      " 20  Timezone               object        \n",
      " 21  Airport_Code           object        \n",
      " 22  Weather_Timestamp      object        \n",
      " 23  Temperature(F)         float64       \n",
      " 24  Wind_Chill(F)          float64       \n",
      " 25  Humidity(%)            float64       \n",
      " 26  Pressure(in)           float64       \n",
      " 27  Visibility(mi)         float64       \n",
      " 28  Wind_Direction         object        \n",
      " 29  Wind_Speed(mph)        float64       \n",
      " 30  Precipitation(in)      float64       \n",
      " 31  Weather_Condition      object        \n",
      " 32  Amenity                bool          \n",
      " 33  Bump                   bool          \n",
      " 34  Crossing               bool          \n",
      " 35  Give_Way               bool          \n",
      " 36  Junction               bool          \n",
      " 37  No_Exit                bool          \n",
      " 38  Railway                bool          \n",
      " 39  Roundabout             bool          \n",
      " 40  Station                bool          \n",
      " 41  Stop                   bool          \n",
      " 42  Traffic_Calming        bool          \n",
      " 43  Traffic_Signal         bool          \n",
      " 44  Turning_Loop           bool          \n",
      " 45  Sunrise_Sunset         object        \n",
      " 46  Civil_Twilight         object        \n",
      " 47  Nautical_Twilight      object        \n",
      " 48  Astronomical_Twilight  object        \n",
      "dtypes: bool(13), datetime64[ns](2), float64(14), int64(1), object(19)\n",
      "memory usage: 853.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_count = df.ID.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                        0.0\n",
       "Source                    0.0\n",
       "TMC                      24.5\n",
       "Severity                  0.0\n",
       "Start_Time                0.0\n",
       "End_Time                  0.0\n",
       "Start_Lat                 0.0\n",
       "Start_Lng                 0.0\n",
       "End_Lat                  75.5\n",
       "End_Lng                  75.5\n",
       "Distance(mi)              0.0\n",
       "Description               0.0\n",
       "Number                   64.5\n",
       "Street                    0.0\n",
       "Side                      0.0\n",
       "City                      0.0\n",
       "County                    0.0\n",
       "State                     0.0\n",
       "Zipcode                   0.0\n",
       "Country                   0.0\n",
       "Timezone                  0.1\n",
       "Airport_Code              0.2\n",
       "Weather_Timestamp         1.2\n",
       "Temperature(F)            1.9\n",
       "Wind_Chill(F)            62.3\n",
       "Humidity(%)               2.0\n",
       "Pressure(in)              1.6\n",
       "Visibility(mi)            2.2\n",
       "Wind_Direction            1.5\n",
       "Wind_Speed(mph)          14.8\n",
       "Precipitation(in)        67.2\n",
       "Weather_Condition         2.2\n",
       "Amenity                   0.0\n",
       "Bump                      0.0\n",
       "Crossing                  0.0\n",
       "Give_Way                  0.0\n",
       "Junction                  0.0\n",
       "No_Exit                   0.0\n",
       "Railway                   0.0\n",
       "Roundabout                0.0\n",
       "Station                   0.0\n",
       "Stop                      0.0\n",
       "Traffic_Calming           0.0\n",
       "Traffic_Signal            0.0\n",
       "Turning_Loop              0.0\n",
       "Sunrise_Sunset            0.0\n",
       "Civil_Twilight            0.0\n",
       "Nautical_Twilight         0.0\n",
       "Astronomical_Twilight     0.0\n",
       "Duration                  0.0\n",
       "Duration(m)               0.0\n",
       "weekday                   0.0\n",
       "hour                      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % null\n",
    "round((df.isna().sum() / orig_count * 100),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time of traffic duration\n",
    "df['Duration'] = df.apply(lambda x: x['End_Time'] - x['Start_Time'], axis = 1)\n",
    "\n",
    "# Convert to minutes\n",
    "df['Duration(m)'] = df['Duration']/np.timedelta64(1,'m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap Start Time and End Time when Duration is negative\n",
    "for i in df.index:\n",
    "    if df.loc[i, 'Duration(m)'] < 0:\n",
    "        t = df.loc[i, 'Start_Time']\n",
    "        df.loc[i, 'Start_Time'] = df.loc[i, 'End_Time']\n",
    "        df.loc[i, 'End_Time'] = t\n",
    "        df.loc[i, 'Duration(m)'] = abs(df.loc[i, 'Duration(m)'])\n",
    "        df.loc[i, 'Duration'] = df.loc[i, 'End_Time'] - df.loc[i, 'Start_Time']\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add day of week column\n",
    "df['weekday'] = df['Start_Time'].apply(lambda x: dt.datetime.strftime(x, '%a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hour column\n",
    "df['hour'] = df['Start_Time'].apply(lambda x: dt.datetime.strftime(x, '%H'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132433, 53)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# End_Lat & _Lng are 75.5% null\n",
    "# Can records have Distance without End coordinates?  Yes\n",
    "df[(df['End_Lat'].isnull() == True) & (df['Distance(mi)'] > 0.1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152280, 53)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can Distance be zero and End_Lat not null?  Yes\n",
    "df[(df['End_Lat'].notnull() == True) & (df['Distance(mi)'] == 0)].shape\n",
    "# End_Lat and End_Lng are not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Street Number is 64.5% null and not required, considering highways and ramps, etc., do not have a street address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201.0    63.544860\n",
       "241.0     7.365377\n",
       "245.0     1.207631\n",
       "229.0     0.761616\n",
       "203.0     0.564563\n",
       "222.0     0.422010\n",
       "244.0     0.375311\n",
       "406.0     0.318290\n",
       "246.0     0.213493\n",
       "202.0     0.203306\n",
       "343.0     0.195909\n",
       "247.0     0.155194\n",
       "236.0     0.071142\n",
       "206.0     0.038899\n",
       "248.0     0.034024\n",
       "339.0     0.026023\n",
       "341.0     0.016945\n",
       "336.0     0.002723\n",
       "200.0     0.002219\n",
       "239.0     0.001816\n",
       "351.0     0.000202\n",
       "Name: TMC, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TMC is 24.5% null, while 63.5% of available points are in one category, and likely not beneficial.\n",
    "# % in TMC categories\n",
    "df.TMC.value_counts() / orig_count * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2974335, 49)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exclude End_Lat, End_Lng, Number (street), and TMC columns\n",
    "df2 = df.drop(['End_Lat', 'End_Lng', 'Number', 'TMC'], axis = 1)\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(779721, 49)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop remaining NaN records\n",
    "df_NoNaN = df2.dropna()\n",
    "df_NoNaN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current subset with no NaN is 26% of original file\n",
    "round( df_NoNaN.ID.count() /  orig_count *100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original file was over 60% null in Precipitation(in) and Wind_Chill(F)\n",
    "# Below is an effort to salvage a greater proportion of records:\n",
    "# Sort on month and zipcode to group similar weather together and replace NaNs with interpolate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zipcode is null in only 0.03% of records, remove null zipcode rows\n",
    "df2 = df2[df2['Zipcode'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shorten zipcode for larger areas\n",
    "df2['Zip2'] = df2['Zipcode'].str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract month\n",
    "df2['Month'] = df2['Start_Time'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Month and Zip code to group similar weather\n",
    "df2.sort_values(by = ['Month', 'Zip2'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate to fill missing records in Precipitation, Wind_Chill and Wind_Speed\n",
    "cols = ['Precipitation(in)', 'Wind_Chill(F)', 'Wind_Speed(mph)']\n",
    "df2[cols] = df2[cols].interpolate(method ='linear', axis = 0, limit_direction = 'both') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete remaining null values in columns with 1-2% missing\n",
    "df2 = df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.9"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retained 97% of original records\n",
    "round((df2.ID.count() / orig_count * 100), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "from scipy import stats\n",
    "\n",
    "def drop_numerical_outliers(df, z_thresh=3):\n",
    "    # Constrains will contain `True` or `False` depending on if it is a value below the threshold.\n",
    "    constrains = df.select_dtypes(include='float64') \\\n",
    "        .apply(lambda x: np.abs(stats.zscore(x)) < z_thresh, result_type='reduce') \\\n",
    "        .all(axis=1)\n",
    "    # Drop (inplace) values set to be rejected\n",
    "    df.drop(df.index[~constrains], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_numerical_outliers(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing outliers leaves 91% of original record count\n",
    "round((df2.ID.count() / orig_count * 100), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output wrangled data\n",
    "df2.to_csv('C:/data/Accidents.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
